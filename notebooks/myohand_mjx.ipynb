{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ssCOanHc8JH_"
   },
   "source": [
    "# Training in Brax\n",
    "\n",
    "Once an environment is created in brax, we can quickly train it using brax's built-in training algorithms. Let's try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 22308,
     "status": "ok",
     "timestamp": 1679686324614,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "kUrAlZTod7t_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyoSuite:> Registering Myo Envs\n"
     ]
    }
   ],
   "source": [
    "#@markdown ## ⚠️ PLEASE NOTE:\n",
    "#@markdown This colab runs best using a GPU runtime.  From the Colab menu, choose Runtime > Change Runtime Type, then select **'GPU'** in the dropdown.\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"JAX_CHECK_TRACER_LEAKS\"] = \"true\"\n",
    "import functools\n",
    "import jax\n",
    "\n",
    "from datetime import datetime\n",
    "from jax import numpy as jp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import HTML, clear_output\n",
    "\n",
    "import brax\n",
    "\n",
    "import flax\n",
    "from brax import envs\n",
    "from brax.io import model\n",
    "from brax.io import json\n",
    "from brax.io import html\n",
    "from brax.training.agents.ppo import train as ppo\n",
    "from brax.training.agents.sac import train as sac\n",
    "\n",
    "from myosuite.mjx.myodm_v0 import TrackEnv\n",
    "\n",
    "if 'COLAB_TPU_ADDR' in os.environ:\n",
    "  from jax.tools import colab_tpu\n",
    "  colab_tpu.setup_tpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'jaxlib.xla_extension.ArrayImpl'> <class 'jaxlib.xla_extension.ArrayImpl'> <class 'jaxlib.xla_extension.ArrayImpl'>\n"
     ]
    }
   ],
   "source": [
    "dof_robot = 29\n",
    "model_path = '/../envs/myo/assets/hand/myohand_object.xml'\n",
    "object_name = 'airplane'\n",
    "reference =  {'time':jp.array((0.0, 4.0)),\n",
    "            'robot':jp.zeros((2, dof_robot)),\n",
    "            'robot_vel':jp.zeros((2, dof_robot)),\n",
    "            'object_init':jp.array((0.0, 0.0, 0.1, 1.0, 0.0, 0.0, 0.0)),\n",
    "            'object':jp.array([ [-.2, -.2, 0.1, 1.0, 0.0, 0.0, -1.0],\n",
    "                                [0.2, 0.2, 0.1, 1.0, 0.0, 0.0, 1.0]])\n",
    "            }\n",
    "\n",
    "env = TrackEnv(model_path=model_path, \n",
    "               object_name=object_name, \n",
    "               reference=reference,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# state = jax.jit(env.reset)(rng=jax.random.PRNGKey(seed=0))\n",
    "\n",
    "# HTML(html.render(env.sys, [state.pipeline_state]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eoyyw6pQ3xVJ"
   },
   "source": [
    "First let's pick an environment and a backend to train an agent in. \n",
    "\n",
    "Recall from the [Brax Basics](https://github.com/google/brax/blob/main/notebooks/basics.ipynb) colab, that the backend specifies which physics engine to use, each with different trade-offs between physical realism and training throughput/speed. The engines generally decrease in physical realism but increase in speed in the following order: `generalized`,  `positional`, then `spring`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMailSDb30t-"
   },
   "source": [
    "# Training\n",
    "\n",
    "Brax provides out of the box the following training algorithms:\n",
    "\n",
    "* [Proximal policy optimization](https://github.com/google/brax/blob/main/brax/training/agents/ppo/train.py)\n",
    "* [Soft actor-critic](https://github.com/google/brax/blob/main/brax/training/agents/sac/train.py)\n",
    "* [Evolutionary strategy](https://github.com/google/brax/blob/main/brax/training/agents/es/train.py)\n",
    "* [Analytic policy gradients](https://github.com/google/brax/blob/main/brax/training/agents/apg/train.py)\n",
    "* [Augmented random search](https://github.com/google/brax/blob/main/brax/training/agents/ars/train.py)\n",
    "\n",
    "Trainers take as input an environment function and some hyperparameters, and return an inference function to operate the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3MA1UYlftuq"
   },
   "source": [
    "# Training\n",
    "\n",
    "Let's train the Ant policy using the `generalized` backend with PPO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "height": 321
    },
    "executionInfo": {
     "elapsed": 190263,
     "status": "ok",
     "timestamp": 1671658344336,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 300
    },
    "id": "FB6G2_Yt4A2m",
    "outputId": "402a0a43-3525-4eca-a425-ffcc71e8db0f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/versag/anaconda3/envs/myosuite/lib/python3.10/site-packages/jax/_src/interpreters/xla.py:132: RuntimeWarning: overflow encountered in cast\n",
      "  return np.asarray(x, dtypes.canonicalize_dtype(x.dtype))\n"
     ]
    }
   ],
   "source": [
    "#@title Training\n",
    "\n",
    "# We determined some reasonable hyperparameters offline and share them here.\n",
    "train_fn = functools.partial(ppo.train, \n",
    "                             num_timesteps=50_000_000, \n",
    "                             num_evals=20, \n",
    "                             reward_scaling=5, \n",
    "                             episode_length=1000, \n",
    "                             normalize_observations=True, \n",
    "                             action_repeat=4, \n",
    "                             unroll_length=50, \n",
    "                             num_minibatches=32, \n",
    "                             num_updates_per_batch=8, \n",
    "                             discounting=0.95, \n",
    "                             learning_rate=3e-4, \n",
    "                             entropy_cost=1e-3, \n",
    "                             num_envs=2048, \n",
    "                             batch_size=256, \n",
    "                             max_devices_per_host=8, \n",
    "                             seed=1)\n",
    "\n",
    "\n",
    "# max_y = {'ant': 8000, 'halfcheetah': 8000, 'hopper': 2500, 'humanoid': 13000, 'humanoidstandup': 75_000, 'reacher': 5, 'walker2d': 5000, 'pusher': 0}[env_name]\n",
    "# min_y = {'reacher': -100, 'pusher': -150}.get(env_name, 0)\n",
    "\n",
    "xdata, ydata = [], []\n",
    "times = [datetime.now()]\n",
    "\n",
    "def progress(num_steps, metrics):\n",
    "  times.append(datetime.now())\n",
    "  xdata.append(num_steps)\n",
    "  ydata.append(metrics['eval/episode_reward'])\n",
    "  clear_output(wait=True)\n",
    "  plt.xlim([0, train_fn.keywords['num_timesteps']])\n",
    "  plt.ylim([0, 10])\n",
    "  plt.xlabel('# environment steps')\n",
    "  plt.ylabel('reward per episode')\n",
    "  plt.plot(xdata, ydata)\n",
    "  plt.show()\n",
    "\n",
    "make_inference_fn, params, _ = train_fn(environment=env, progress_fn=progress)\n",
    "\n",
    "print(f'time to jit: {times[1] - times[0]}')\n",
    "print(f'time to train: {times[-1] - times[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bjlh7puy2ZM1"
   },
   "source": [
    "The trainers return an inference function, parameters, and the final set of metrics gathered during evaluation.\n",
    "\n",
    "# Saving and Loading Policies\n",
    "\n",
    "Brax can save and load trained policies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gOWeDqlP35sI"
   },
   "outputs": [],
   "source": [
    "model.save_params('/tmp/params', params)\n",
    "params = model.load_params('/tmp/params')\n",
    "inference_fn = make_inference_fn(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4YlZvIG320sK"
   },
   "source": [
    "The trainers return an inference function, parameters, and the final set of metrics gathered during evaluation.\n",
    "\n",
    "# Saving and Loading Policies\n",
    "\n",
    "Brax can save and load trained policies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "height": 480
    },
    "executionInfo": {
     "elapsed": 33520,
     "status": "ok",
     "timestamp": 1679346718844,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 240
    },
    "id": "kF5fS-yo35sI",
    "outputId": "94d1a7d5-8d6e-456c-8cfd-94a689b8808f"
   },
   "outputs": [],
   "source": [
    "#@title Visualizing a trajectory of the learned inference function\n",
    "\n",
    "# create an env with auto-reset\n",
    "env = envs.create(env_name=env_name, backend=backend)\n",
    "\n",
    "jit_env_reset = jax.jit(env.reset)\n",
    "jit_env_step = jax.jit(env.step)\n",
    "jit_inference_fn = jax.jit(inference_fn)\n",
    "\n",
    "rollout = []\n",
    "rng = jax.random.PRNGKey(seed=1)\n",
    "state = jit_env_reset(rng=rng)\n",
    "for _ in range(1000):\n",
    "  rollout.append(state.pipeline_state)\n",
    "  act_rng, rng = jax.random.split(rng)\n",
    "  act, _ = jit_inference_fn(state.obs, act_rng)\n",
    "  state = jit_env_step(state, act)\n",
    "\n",
    "HTML(html.render(env.sys.tree_replace({'opt.timestep': env.dt}), rollout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CBtrAqns35sI"
   },
   "source": [
    "🙌 See you soon!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
